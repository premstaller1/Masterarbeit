{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Cleaning\n",
    "This notebook was in general used for cleaning and preparation of datasets, both for Hydrogen and the Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/125.4 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 41.0/125.4 kB 667.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 125.4/125.4 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Requirement already satisfied: openpyxl in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openpyxl) (1.1.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/61.0 kB 660.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/11.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 10.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.9/11.6 MB 16.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.7/11.6 MB 16.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.6 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.6 MB 18.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.1/11.6 MB 17.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.1/11.6 MB 17.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.6 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.1/11.6 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 17.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.7/15.8 MB 13.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/15.8 MB 15.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 15.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.8/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.7/15.8 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 16.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/15.8 MB 16.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.1/15.8 MB 16.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.6/15.8 MB 17.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.2/15.8 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.1/15.8 MB 17.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.8 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.9/15.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.4/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.8 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 505.5/505.5 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\osi0pr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2024.2.2)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 10.2/62.6 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 10.2/62.6 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 30.7/62.6 kB 435.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 62.6/62.6 kB 556.7 kB/s eta 0:00:00\n",
      "Installing collected packages: requests\n",
      "Successfully installed requests-2.31.0\n"
     ]
    }
   ],
   "source": [
    "#Install necessaty libraries and packages\n",
    "!pip install geopy\n",
    "!pip install openpyxl\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the initial data attained from the france hydrogen association was cleaned and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/199.4 kB 445.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 174.1/199.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import chardet\n",
    "\n",
    "# List to store the cleaned data\n",
    "clean_data = []\n",
    "\n",
    "# Open the CSV file with 'rb' mode to read in binary mode\n",
    "with open(r'C:\\Users\\osi0pr\\Documents\\Github\\Masterarbeit\\webcrawler\\data\\france_member.csv', 'rb') as file:\n",
    "    # Use chardet to detect the encoding of the file\n",
    "    result = chardet.detect(file.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "# Open the CSV file with the detected encoding\n",
    "with open(r'C:\\Users\\osi0pr\\Documents\\Github\\Masterarbeit\\webcrawler\\data\\france_member.csv', 'r', encoding=encoding) as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Skip the header row\n",
    "    next(reader)\n",
    "\n",
    "    # Iterate through each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Split the address by newline character(s)\n",
    "        address_parts = row[2].replace('\\r', '').split('\\n')\n",
    "\n",
    "        # Clean and join the address parts\n",
    "        cleaned_address = ' '.join(address_parts)\n",
    "\n",
    "        # Create a new row with the cleaned address\n",
    "        new_row = [row[0], row[1], cleaned_address]\n",
    "\n",
    "        # Add the new row to the clean_data list\n",
    "        clean_data.append(new_row)\n",
    "\n",
    "# Open a new CSV file to write the cleaned data\n",
    "with open(r'C:\\Users\\osi0pr\\Documents\\Github\\Masterarbeit\\webcrawler\\data\\france_member_cleaned.csv', 'w', newline='', encoding=encoding) as new_file:\n",
    "    writer = csv.writer(new_file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(['Name', 'Representative', 'Address'])\n",
    "\n",
    "    # Write the clean_data rows\n",
    "    writer.writerows(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was used to combine the data gathered from: https://www.wasserstoff-leitprojekte.de/leitprojekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the distributed data into a pandas dataframe\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('../Gis/data/data-krTLV.csv')\n",
    "df2 = pd.read_csv('../Gis/data/data-MDu07.csv')\n",
    "df3 = pd.read_csv('../Gis/data/data-ZhFqn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename spatial columns to the same name\n",
    "df1['Latitude'] = df1['LAT']\n",
    "df1['Longitude'] = df1['LON']\n",
    "df2['Latitude'] = df2['Lat']\n",
    "df2['Longitude'] = df2['Lon']\n",
    "df3['Latitude'] = df3['Lat']\n",
    "df3['Longitude'] = df3['Lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns that are not needed\n",
    "df1.drop(['LAT', 'LON', 'Title'], axis=1, inplace=True)\n",
    "df2.drop(['Lat', 'Lon', 'Title', 'Column 1'], axis=1, inplace=True)\n",
    "df3.drop(['Lat', 'Lon'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes and clean up the format of the columns. Delete duplicates\n",
    "frames = [df1, df2, df3]\n",
    "merge_df = pd.concat(frames)\n",
    "\n",
    "#merge columns together for full address\n",
    "merge_df['Full Address'] = merge_df['Straße'] + ', ' + merge_df['Ort'] + ', ' + merge_df['PLZ'].astype(str) + ', ' + merge_df['Land'].astype(str)\n",
    "\n",
    "#delete duplicates in Column \"Partner ohne Markdown\"\n",
    "merge_df = merge_df.drop_duplicates(subset='Partner ohne Markdown', keep='first')\n",
    "\n",
    "merge_df\n",
    "merge_df.to_excel('deutschland_projecte.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataframe for our benchmark data, which we got from the Amadeus database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "        Unnamed: 0                        Name des Unternehmens Länderkürzel  \\\n",
      "0              1.0                                    UNIPER SE           DE   \n",
      "1              2.0                        ELECTRICITE DE FRANCE           FR   \n",
      "2              3.0                                   ENI S.P.A.           IT   \n",
      "3              4.0  GESTORE DEI SERVIZI ENERGETICI - GSE S.P.A.           IT   \n",
      "4              5.0               VATTENFALL ENERGY TRADING GMBH           DE   \n",
      "...            ...                                          ...          ...   \n",
      "105755    105756.0          ZWÖLFTE SOLARKRAFTWERK SCHWEDT GMBH           DE   \n",
      "105756    105757.0        ZWÖLFTE WINDKRAFTANLAGE GMBH & CO. KG           DE   \n",
      "105757    105758.0                     ZWOLPOL PATRYK ZWOLIŃSKI           PL   \n",
      "105758    105759.0                                   ZZ ECOTECH           BE   \n",
      "105759    105760.0     ZZS ZEITZUSPAREN UG (HAFTUNGSBESCHRÄNKT)           DE   \n",
      "\n",
      "                             Adresse Postleitzahl         Ort         Land  \n",
      "0                         HOLZSTR. 6        40221  DÜSSELDORF  Deutschland  \n",
      "1                22 AVENUE DE WAGRAM        75008       PARIS   Frankreich  \n",
      "2                PLE ENRICO MATTEI 1        00144        ROMA      Italien  \n",
      "3       VLE MARESCIALLO PILSUDSKI 92        00197        ROMA      Italien  \n",
      "4                 DAMMTORSTR. 29- 32        20354     HAMBURG  Deutschland  \n",
      "...                              ...          ...         ...          ...  \n",
      "105755           SCHMALENBACHSTR. 22        12057      BERLIN  Deutschland  \n",
      "105756              STAHLTWIETE 21 A        22761     HAMBURG  Deutschland  \n",
      "105757    STEFANA JARACZA 17 LOK. 32       90-261        ŁÓDŹ        Polen  \n",
      "105758              BRUSSELSTRAAT 51         2018   ANTWERPEN      Belgien  \n",
      "105759                           NaN          NaN        KÖLN  Deutschland  \n",
      "\n",
      "[105760 rows x 7 columns]\n",
      "\n",
      "Subset Data:\n",
      "       Unnamed: 0                              Name des Unternehmens  \\\n",
      "0         91208.0       RWE RENEWABLES OFFSHORE DEVELOPMENT ONE GMBH   \n",
      "1         60963.0                   BRELOH WINDENERGIE GMBH & CO. KG   \n",
      "2         69504.0          ENOVA WINDPARK PANTEN-BÄLAU GMBH & CO. KG   \n",
      "3         66219.0       ECOSENERGY BETRIEBSGESELLSCHAFT MBH & CO. KG   \n",
      "4         78772.0  KEB KOMMUNALE ENERGIEVERSORGUNG BRAND-ERBISDOR...   \n",
      "...           ...                                                ...   \n",
      "29989     69422.0                                ENKELE ENERGIE B.V.   \n",
      "29990      3369.0                                WINDPARK MAUVE B.V.   \n",
      "29991     75319.0                      HALLOSTROOM HUUR ZON XII B.V.   \n",
      "29992    100415.0                  WARMTELEVERING WONEN LIMBURG B.V.   \n",
      "29993    105313.0  ZONNE ENERGIE COÖPERATIE SLUIS-OOSTBURG (BELDE...   \n",
      "\n",
      "      Länderkürzel                         Adresse Postleitzahl  \\\n",
      "0               DE                     RWE PLATZ 4        45141   \n",
      "1               DE                HALENE-KAMPEN 55        59227   \n",
      "2               DE               STEINHAUSSTR. 112        26831   \n",
      "3               DE                      ERNSTHOF 9        97877   \n",
      "4               DE              AN DER ZUGSPITZE 9        09618   \n",
      "...            ...                             ...          ...   \n",
      "29989           NL  KRONENBURGSINGEL 525 (P/A KVK)      6831 GM   \n",
      "29990           NL                PARNASSUSWEG 821      1082 LZ   \n",
      "29991           NL              BOUWMEESTERPLEIN 1      2801 BX   \n",
      "29992           NL             WILLEM II SINGEL 25      6041 HP   \n",
      "29993           NL                   LAURINAWEG 13      4522 GZ   \n",
      "\n",
      "                   Ort         Land  \n",
      "0                ESSEN  Deutschland  \n",
      "1                AHLEN  Deutschland  \n",
      "2                BUNDE  Deutschland  \n",
      "3             WERTHEIM  Deutschland  \n",
      "4      BRAND-ERBISDORF  Deutschland  \n",
      "...                ...          ...  \n",
      "29989           ARNHEM  Niederlande  \n",
      "29990        AMSTERDAM  Niederlande  \n",
      "29991            GOUDA  Niederlande  \n",
      "29992         ROERMOND  Niederlande  \n",
      "29993        BIERVLIET  Niederlande  \n",
      "\n",
      "[29994 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create the dataframe for our benchmark data, which we will use to create a subset.\n",
    "#The subset will have the same distribution of values in the 'Land' column as the original data.\n",
    "#This will ensure that the subset is representative of the original data in terms of the distribution of countries.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('locations/amadeus_benchmark_V1.xlsx')\n",
    "\n",
    "# Define the desired number of rows in the subset\n",
    "desired_subset_size = 30000\n",
    "\n",
    "# Define the column you want to keep relatively consistent\n",
    "desired_column = 'Land'\n",
    "\n",
    "# Create a list of unique values in the desired column\n",
    "unique_values = df[desired_column].unique()\n",
    "\n",
    "# Calculate the current distribution of the desired column\n",
    "current_distribution = df[desired_column].value_counts(normalize=True)\n",
    "\n",
    "# Create an empty list to store the subset data\n",
    "subset_data = []\n",
    "\n",
    "# Sample rows from the original data based on the desired distribution\n",
    "for value in unique_values:\n",
    "    num_rows = int(desired_subset_size * current_distribution[value])\n",
    "    subset_rows = df[df[desired_column] == value].sample(n=num_rows, replace=True)\n",
    "    subset_data.append(subset_rows)\n",
    "\n",
    "# Concatenate the sampled rows to create the final subset DataFrame\n",
    "subset_df = pd.concat(subset_data, ignore_index=True)\n",
    "\n",
    "# Display the original data\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Display the subset data\n",
    "print(\"\\nSubset Data:\")\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.to_excel('locations/amadeus_benchmark_V2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
