# Kernel density estimation
industry_density <- density(di_industry)
bench_density <- density(di_bench)
# Plot the densities
plot(industry_density, main = "Density of Di Values", xlab = "Di Values", ylab = "Density")
lines(bench_density, lty = 2)
legend("topright", legend = c("Industry", "Benchmark"), lty = c(1, 2), col = c("black", "black"))
# Compare the densities
intersect_points <- industry_density$x[industry_density$y > bench_density$y]
cat("Intersection points:", intersect_points, "\n")
# Calculate kernel density estimates (kde) for observed and benchmark data
kdeObs <- density(di_industry)
kdeBench <- density(di_bench)
# Call the globalValues function with the kdeObs and kdeBench as arguments
globalValuesResult <- globalValues(kdeObs, kdeBench)
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.85)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.90)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
# Load required packages
library(readxl)
library(sp)
library(raster)
bilatDistance <- function(lo, la){ # gives correctly computed bilateral distancs in km
radj=6371
la <- 2 * pi * la/360
lo <- 2 * pi * lo/360
coslat <- cos(la)
sinlat <- sin(la)
dvect <- sinlat %o% sinlat + (coslat %o% coslat) * cos(-outer(lo,  lo, "-"))
dvect <- dvect[lower.tri(dvect)]
dvect <- ifelse(dvect > 1, 1, dvect)
dvect <- radj * acos(dvect)
return(dvect)
}
convertXY<- function(lat,lon){
R=6371000
x = R * (cos(9000-lat)* cos(lon))
y = R * (cos(9000-lat) *sin(lon))
ergeb=objects();
ergeb$x=x
ergeb$y=y
return (ergeb)
}
calcDi<- function(y,x, fun){
thresh=1 # min distance
dist=bilatDistance(y,x)# calculaution of bilateral distances according to McSpatial
dist[dist<thresh] <-thresh
Di=rep(0,length(y))
pos=1
i=1
for(i in 1:(length(Di)-1)){ # calculate Di vlaues
upTo=length(Di)-i # length of array
#print(paste("Von ",pos,"um",upTo, sep=" " ))
for(z in 1:upTo){ # different possible functions to play with --> use invert
if(fun=="invert" ){
val=1/(dist[pos]*(length(Di)-1));
}
if(fun=="expo"){
val=exp(-0.05*dist[pos])
val=val/(length(Di)-1)
}
Di[i]=Di[i]+val
mypos=i+z
Di[mypos]=Di[mypos]+val
# print(paste("Updaze bei",i,"und",mypos, sep=" " ))
#print(pos)
pos=pos+1
}
}
return (Di)
}
getPercentileGlobalConfidenceBand <- function (KDEValues,esp, maxNumb,numIter, startPercentile, percentileStep, upperOrLower){
counter=0
observedNumb=maxNumb+1
while(observedNumb>maxNumb){
bound=vector();
counter=counter+1
for(i in 1:esp){
if(upperOrLower=="lower"){
percentile=startPercentile-(counter*percentileStep)
}
else{
percentile=startPercentile+(counter*percentileStep)
}
quantiles <- quantile(KDEValues[,i], percentile)
bound=append(bound,quantiles[[1]])
}
observedNumb=0
for(i in 1:numIter){# WIe oft wird der Bound getroffen
iter=KDEValues[i,]
if(upperOrLower=="lower"){
if(sum(iter<bound)>=1){ # Bound wurden an mindestens einer Stelle getroffen
observedNumb=observedNumb+1
}
}
else{
if(sum(iter>bound)>=1){ # Bound wurden an mindestens einer Stelle getroffen
observedNumb=observedNumb+1
}
}
}
print(paste("Percenetik:",percentile, " Treffer: ",observedNumb))
}
ergeb=objects();
ergeb$bound=bound;
ergeb$percentile=percentile
return (ergeb)
}
globalConfidenceBand <- function (KDEValues,esp, thresh){
numIter=length(KDEValues[,1])
maxNumb=(thresh/100)*numIter
print(maxNumb)
#Calclulation of lower Bound at 1 % Steps
lowerBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, 0.05, 0.01, "lower")
#Calclulation of lower Bound at 0.1 % Steps
start=lowerBoundCalc$percentile+0.01 # set last position
lowerBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, start, 0.001, "lower")
#Calclulation of upper Bound at 1 % Steps
upperBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, 0.95, 0.01, "upper")
#Calclulation of upper Bound at 0.1 % Steps
start=upperBoundCalc$percentile-0.01 # set last position
upperBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, start, 0.001, "upper")
ergeb=objects(); # ergeb means result in German ;)
ergeb$lowerBound=lowerBoundCalc$bound
ergeb$upperBound=upperBoundCalc$bound
ergeb$KDEValues=KDEValues
return (ergeb)
}
# calculate local confidence Bands ( not used in Paper)
localConfidenceBand <- function (KDEValues,esp){
lowerBound=vector();
upperBound=vector();
for(i in 1:esp){
quantiles <- quantile(KDEValues[,i], c(.05,.95))
lowerBound=append(lowerBound,quantiles[[1]])
upperBound=append(upperBound,quantiles[[2]])
}
ergeb=objects();
ergeb$lowerBound=lowerBound
ergeb$upperBound=upperBound
return (ergeb)
}
#####  Global Values  ###################################################################################################
# function is used to calculate global dispersion or concentration
# needs the calculated Di values of the observes industry and the bechmark
globalValues<- function (kdeObs, kdeBench){
#calculate the median value of Benchmark
meanIntegral=0
i=1
while (meanIntegral<0.5){
maxb=max(kdeBench$y[i],kdeBench$y[(i+1)])
d=abs(kdeBench$y[i]-kdeBench$y[(i+1)])
c=kdeBench$x[(i+1)]-kdeBench$x[i]
integral=maxb*c-(0.5*(c*d))
meanIntegral=meanIntegral+integral
i=i+1
}
myMean=kdeBench$x[i]
omega=0
theta=0
print(myMean)
for(i in 1:(length(kdeObs$y)-1)){
if(kdeObs$y[i]>kdeBench$y[i] && kdeObs$y[(i+1)]>kdeBench$y[(i+1)]){
maxbObs=max(kdeObs$y[i],kdeObs$y[(i+1)])
maxbBench=max(kdeBench$y[i],kdeBench$y[(i+1)])
dObs=abs(kdeObs$y[i]-kdeObs$y[(i+1)])
dBench=abs(kdeBench$y[i]-kdeBench$y[(i+1)])
c=kdeObs$x[(i+1)]-kdeObs$x[i]
integralObs=maxbObs*c-(0.5*(c*dObs))
integralBench=maxbBench*c-(0.5*(c*dBench))
integral=integralObs-integralBench
if(kdeBench$x[i]< myMean){#Dispersion
omega=omega+integral
#print(paste("Dispersion an der Stelle",kdeObs$x[i],"mit Wert",kdeObs$y[i],"zu",kdeBench$y[i], "ergibt:",integral, sep=" "))
}
else{#Concentration
theta=theta+integral
#print(paste("Konzentration an der Stelle",kdeObs$x[i],"mit Wert",kdeObs$y[i],"zu",kdeBench$y[i], "ergibt:",integral, sep=" "))
}
}
}
ergeb=objects();
ergeb$theta=theta
ergeb$omega=omega
ergeb$delta=theta-omega
ergeb$myMean=myMean
return (ergeb)
}
globalValuesResult <- globalValues(kdeObs, kdeBench)
# Print the result
print(globalValuesResult)
# Load required packages
#install.packages("McSpatial")
#install.packages("fields")
library(readxl)
library(ggplot2)
library(gridExtra)
library(MASS)
library(ks)
library(stats) # For Mann-Whitney U test
# Load the test and benchmark datasets
locations_industry <- read_excel("data/locations_hydro_V10.xlsx")
locations_bench <- read_excel("data/amadeus_benchmark_V3.xlsx")
# Extract latitude and longitude values
industry_lat <- locations_industry$Lat
industry_lon <- locations_industry$Lon
bench_lat <- locations_bench$Latitude
bench_lon <- locations_bench$Longitude
# Calculate Di values for both populations
#library(McSpatial)
#library(fields)
di_industry <- calcDi(industry_lat, industry_lon, fun = "invert")
di_bench <- calcDi(bench_lat, bench_lon, fun = "invert")
# 1. Kolmogorov-Smirnov Test
ks.test(di_industry, di_bench)
# 2. Mann-Whitney U Test
wilcox.test(di_industry, di_bench, alternative = "two.sided")
# 3. Kernel Density Estimation and Comparison
library(stats)
# Kernel density estimation
industry_density <- density(di_industry)
bench_density <- density(di_bench)
# Plot the densities
plot(industry_density, main = "Density of Di Values", xlab = "Di Values", ylab = "Density")
lines(bench_density, lty = 2)
legend("topright", legend = c("Industry", "Benchmark"), lty = c(1, 2), col = c("black", "black"))
# Compare the densities
intersect_points <- industry_density$x[industry_density$y > bench_density$y]
cat("Intersection points:", intersect_points, "\n")
# Calculate kernel density estimates (kde) for observed and benchmark data
kdeObs <- density(di_industry)
kdeBench <- density(di_bench)
# Call the globalValues function with the kdeObs and kdeBench as arguments
globalValuesResult <- globalValues(kdeObs, kdeBench)
# Print the result
print(globalValuesResult)
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.90)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
# Load required packages
library(readxl)
library(sp)
library(raster)
bilatDistance <- function(lo, la){ # gives correctly computed bilateral distancs in km
radj=6371
la <- 2 * pi * la/360
lo <- 2 * pi * lo/360
coslat <- cos(la)
sinlat <- sin(la)
dvect <- sinlat %o% sinlat + (coslat %o% coslat) * cos(-outer(lo,  lo, "-"))
dvect <- dvect[lower.tri(dvect)]
dvect <- ifelse(dvect > 1, 1, dvect)
dvect <- radj * acos(dvect)
return(dvect)
}
convertXY<- function(lat,lon){
R=6371000
x = R * (cos(9000-lat)* cos(lon))
y = R * (cos(9000-lat) *sin(lon))
ergeb=objects();
ergeb$x=x
ergeb$y=y
return (ergeb)
}
calcDi<- function(y,x, fun){
thresh=1 # min distance
dist=bilatDistance(y,x)# calculaution of bilateral distances according to McSpatial
dist[dist<thresh] <-thresh
Di=rep(0,length(y))
pos=1
i=1
for(i in 1:(length(Di)-1)){ # calculate Di vlaues
upTo=length(Di)-i # length of array
#print(paste("Von ",pos,"um",upTo, sep=" " ))
for(z in 1:upTo){ # different possible functions to play with --> use invert
if(fun=="invert" ){
val=1/(dist[pos]*(length(Di)-1));
}
if(fun=="expo"){
val=exp(-0.05*dist[pos])
val=val/(length(Di)-1)
}
Di[i]=Di[i]+val
mypos=i+z
Di[mypos]=Di[mypos]+val
# print(paste("Updaze bei",i,"und",mypos, sep=" " ))
#print(pos)
pos=pos+1
}
}
return (Di)
}
getPercentileGlobalConfidenceBand <- function (KDEValues,esp, maxNumb,numIter, startPercentile, percentileStep, upperOrLower){
counter=0
observedNumb=maxNumb+1
while(observedNumb>maxNumb){
bound=vector();
counter=counter+1
for(i in 1:esp){
if(upperOrLower=="lower"){
percentile=startPercentile-(counter*percentileStep)
}
else{
percentile=startPercentile+(counter*percentileStep)
}
quantiles <- quantile(KDEValues[,i], percentile)
bound=append(bound,quantiles[[1]])
}
observedNumb=0
for(i in 1:numIter){# WIe oft wird der Bound getroffen
iter=KDEValues[i,]
if(upperOrLower=="lower"){
if(sum(iter<bound)>=1){ # Bound wurden an mindestens einer Stelle getroffen
observedNumb=observedNumb+1
}
}
else{
if(sum(iter>bound)>=1){ # Bound wurden an mindestens einer Stelle getroffen
observedNumb=observedNumb+1
}
}
}
print(paste("Percenetik:",percentile, " Treffer: ",observedNumb))
}
ergeb=objects();
ergeb$bound=bound;
ergeb$percentile=percentile
return (ergeb)
}
globalConfidenceBand <- function (KDEValues,esp, thresh){
numIter=length(KDEValues[,1])
maxNumb=(thresh/100)*numIter
print(maxNumb)
#Calclulation of lower Bound at 1 % Steps
lowerBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, 0.05, 0.01, "lower")
#Calclulation of lower Bound at 0.1 % Steps
start=lowerBoundCalc$percentile+0.01 # set last position
lowerBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, start, 0.001, "lower")
#Calclulation of upper Bound at 1 % Steps
upperBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, 0.95, 0.01, "upper")
#Calclulation of upper Bound at 0.1 % Steps
start=upperBoundCalc$percentile-0.01 # set last position
upperBoundCalc=getPercentileGlobalConfidenceBand(KDEValues,esp, maxNumb,numIter, start, 0.001, "upper")
ergeb=objects(); # ergeb means result in German ;)
ergeb$lowerBound=lowerBoundCalc$bound
ergeb$upperBound=upperBoundCalc$bound
ergeb$KDEValues=KDEValues
return (ergeb)
}
# calculate local confidence Bands ( not used in Paper)
localConfidenceBand <- function (KDEValues,esp){
lowerBound=vector();
upperBound=vector();
for(i in 1:esp){
quantiles <- quantile(KDEValues[,i], c(.05,.95))
lowerBound=append(lowerBound,quantiles[[1]])
upperBound=append(upperBound,quantiles[[2]])
}
ergeb=objects();
ergeb$lowerBound=lowerBound
ergeb$upperBound=upperBound
return (ergeb)
}
#####  Global Values  ###################################################################################################
# function is used to calculate global dispersion or concentration
# needs the calculated Di values of the observes industry and the bechmark
globalValues<- function (kdeObs, kdeBench){
#calculate the median value of Benchmark
meanIntegral=0
i=1
while (meanIntegral<0.5){
maxb=max(kdeBench$y[i],kdeBench$y[(i+1)])
d=abs(kdeBench$y[i]-kdeBench$y[(i+1)])
c=kdeBench$x[(i+1)]-kdeBench$x[i]
integral=maxb*c-(0.5*(c*d))
meanIntegral=meanIntegral+integral
i=i+1
}
myMean=kdeBench$x[i]
omega=0
theta=0
print(myMean)
for(i in 1:(length(kdeObs$y)-1)){
if(kdeObs$y[i]>kdeBench$y[i] && kdeObs$y[(i+1)]>kdeBench$y[(i+1)]){
maxbObs=max(kdeObs$y[i],kdeObs$y[(i+1)])
maxbBench=max(kdeBench$y[i],kdeBench$y[(i+1)])
dObs=abs(kdeObs$y[i]-kdeObs$y[(i+1)])
dBench=abs(kdeBench$y[i]-kdeBench$y[(i+1)])
c=kdeObs$x[(i+1)]-kdeObs$x[i]
integralObs=maxbObs*c-(0.5*(c*dObs))
integralBench=maxbBench*c-(0.5*(c*dBench))
integral=integralObs-integralBench
if(kdeBench$x[i]< myMean){#Dispersion
omega=omega+integral
#print(paste("Dispersion an der Stelle",kdeObs$x[i],"mit Wert",kdeObs$y[i],"zu",kdeBench$y[i], "ergibt:",integral, sep=" "))
}
else{#Concentration
theta=theta+integral
#print(paste("Konzentration an der Stelle",kdeObs$x[i],"mit Wert",kdeObs$y[i],"zu",kdeBench$y[i], "ergibt:",integral, sep=" "))
}
}
}
ergeb=objects();
ergeb$theta=theta
ergeb$omega=omega
ergeb$delta=theta-omega
ergeb$myMean=myMean
return (ergeb)
}
# Load the test and benchmark datasets
locations_industry <- read_excel("data/locations_hydro_V10.xlsx")
locations_bench <- read_excel("data/amadeus_benchmark_V3.xlsx")
# Extract latitude and longitude values
industry_lat <- locations_industry$Lat
industry_lon <- locations_industry$Lon
bench_lat <- locations_bench$Latitude
bench_lon <- locations_bench$Longitude
benchmark_xy <- convertXY(bench_lat, bench_lon)
industry_xy <- convertXY(industry_lat, industry_lon)
View(benchmark_xy)
View(benchmark_xy)
benchmark_xy
# Load required packages
#install.packages("McSpatial")
#install.packages("fields")
library(readxl)
library(ggplot2)
library(gridExtra)
library(MASS)
library(ks)
library(stats) # For Mann-Whitney U test
# Load the test and benchmark datasets
locations_industry <- read_excel("data/locations_hydro_V10.xlsx")
locations_bench <- read_excel("data/amadeus_benchmark_V3.xlsx")
# Extract latitude and longitude values
industry_lat <- locations_industry$Lat
industry_lon <- locations_industry$Lon
bench_lat <- locations_bench$Latitude
bench_lon <- locations_bench$Longitude
benchmark_xy <- convertXY(bench_lat, bench_lon)
industry_xy <- convertXY(industry_lat, industry_lon)
# Calculate Di values for both populations
#library(McSpatial)
#library(fields)
di_industry <- calcDi(industry_xy$x, industry_xy$y, fun = "invert")
di_bench <- calcDi(benchmark_xy$x, benchmark_xy$y, fun = "invert")
# 1. Kolmogorov-Smirnov Test
ks.test(di_industry, di_bench)
# 2. Mann-Whitney U Test
wilcox.test(di_industry, di_bench, alternative = "two.sided")
# 3. Kernel Density Estimation and Comparison
library(stats)
# Kernel density estimation
#industry_density <- density(di_industry)
#bench_density <- density(di_bench)
# Plot the densities
plot(industry_density, main = "Density of Di Values", xlab = "Di Values", ylab = "Density")
# 3. Kernel Density Estimation and Comparison
library(stats)
# Kernel density estimation
industry_density <- density(di_industry)
bench_density <- density(di_bench)
# Plot the densities
plot(industry_density, main = "Density of Di Values", xlab = "Di Values", ylab = "Density")
lines(bench_density, lty = 2)
legend("topright", legend = c("Industry", "Benchmark"), lty = c(1, 2), col = c("black", "black"))
# Compare the densities
intersect_points <- industry_density$x[industry_density$y > bench_density$y]
cat("Intersection points:", intersect_points, "\n")
# Calculate kernel density estimates (kde) for observed and benchmark data
kdeObs <- density(di_industry)
kdeBench <- density(di_bench)
# Call the globalValues function with the kdeObs and kdeBench as arguments
globalValuesResult <- globalValues(kdeObs, kdeBench)
# Print the result
print(globalValuesResult)
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.95)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.90)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
# Calculate the 95th percentile of Di values for the benchmark population
bench_95th_percentile <- quantile(di_bench, 0.70)
# Identify firms in the industry population that exceed the 95th percentile
cluster_cores <- di_industry > bench_95th_percentile
# Count the number of firms in the cluster cores
num_cluster_cores <- sum(cluster_cores)
cat("Number of firms in cluster cores:", num_cluster_cores, "\n")
